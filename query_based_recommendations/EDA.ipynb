{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ef50509-652f-400a-920a-066a4e13cdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m17.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:19\u001b[0m\n",
      "\u001b[?25hCollecting numpy\n",
      "  Downloading numpy-1.26.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/18.2 MB\u001b[0m \u001b[31m13.6 kB/s\u001b[0m eta \u001b[36m0:15:56\u001b[0m^C7\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/18.2 MB\u001b[0m \u001b[31m13.6 kB/s\u001b[0m eta \u001b[36m0:15:56\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01a068f6-b809-433a-acd1-7bd650602cb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6f818f-53ca-47e5-9560-19c57622f85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None # Display all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f44d374-b9a9-468a-952f-d80b2a6574af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0c1ca4-e669-4878-8c39-811cfe8e9940",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"data/Joshua_Tree_Airbnb_Raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c601bb-2468-4420-862d-cc449ddae20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b19700-7d7b-419e-bafa-bacb64b3fb6e",
   "metadata": {},
   "source": [
    "Identifying Columns of Interest\n",
    "- Address\n",
    "- Name\n",
    "- Reviews/0-9/comments\n",
    "It seems this dataset do not contain any column that has a description of of the corresponding hotel. Lets try another airbnb dataset. More specifically,[[https://www.kaggle.com/datasets/tylerx/melbourne-airbnb-open-data][this one]]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbb7c97-9cfd-4039-8735-906987ffd3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings = pd.read_csv('data/listings_summary_dec18.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333153b5-7363-450e-9c79-27df78bf8681",
   "metadata": {},
   "source": [
    "- Interestingly, description would be a bad context. Rather, we need to look at how users describe a hotel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55fc0f1-dc49-426d-b9ce-4b3f1b2c8ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = [\"address\",\"name\",\"reviews/0/comments\",\"reviews/1/comments\",\"reviews/2/comments\",\"reviews/3/comments\",\"reviews/4/comments\",\"reviews/5/comments\",\"reviews/6/comments\",\"reviews/7/comments\",\"reviews/8/comments\",\"reviews/9/comments\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93255d1a-0083-4ddc-8625-303307b22617",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71dac44-4f9f-4f0c-862e-d7de19133e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90cc735-c994-403f-9aaf-05956781b598",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7458931-d039-4b5d-8df9-1764ff1818d8",
   "metadata": {},
   "source": [
    "## Missing Value Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefa0b15-06b3-4b50-a5cb-ed37f99b33a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb9ebc1-be0f-44e7-b1bb-b2c790d4150b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45e669a-f0d7-49ce-92e9-2e2eff358ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead32775-b5c6-49c6-881c-64d8eedf9390",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecc71d7-db0a-49f3-ae5a-81ed75fc4951",
   "metadata": {},
   "source": [
    "## Create Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460cff9e-fe48-4566-a85c-78c578f612b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_to_tagged_document(row):\n",
    "    comments = [str(row[f'reviews/{i}/comments']) for i in range(10)]\n",
    "    words = ' '.join(comments).split()  \n",
    "    tags = [row['name']]\n",
    "    return TaggedDocument(words=words, tags=tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549730b4-25b3-4ad3-a5b5-5cf89af532bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_documents = dataset.apply(row_to_tagged_document, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9992882-b2e6-46a8-9c80-0c5aa12bdca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2cb036-1ce8-407e-92a9-2fc31de2daf7",
   "metadata": {},
   "source": [
    "## Train Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12a1b41-98a4-4d70-90b1-1e27eb353678",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gensim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7bfe20-7378-42cc-9caf-dd5ad6b25565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "model = Doc2Vec(vector_size=50,  # Dimensionality of the document vectors\n",
    "                window=2,         # Maximum distance between the current and predicted word within a sentence\n",
    "                min_count=1,      # Ignores all words with total frequency lower than this\n",
    "                workers=4,        # Number of CPU cores to use for training\n",
    "                epochs=20)        # Number of training epochs\n",
    "\n",
    "# Build the vocabulary\n",
    "model.build_vocab(tagged_documents)\n",
    "\n",
    "# Train the model\n",
    "model.train(tagged_documents, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aabebdb-7ebe-4d13-9cc0-375440245ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"doc2vec_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb7630f-fd24-4ed9-ae46-11d395a64562",
   "metadata": {},
   "source": [
    "## Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96360a0-2a58-4157-bca0-f24de04d81bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vectors = [model.dv[idx] for idx in range(530)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729a612c-9a4c-4b9c-b70e-0bf5982ba52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dataset[\"name\"][:530]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a94c81-b632-416f-a28a-e91ed9e6ac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(doc_vectors, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04a17bc-8fe7-470f-999b-10052f97a67d",
   "metadata": {},
   "source": [
    "### Trying logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cfb70e-e9a5-4ed3-8449-e2e8fd579c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Initialize and train a logistic regression classifier\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "# Make predictions on the test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52d46a1-af68-42cb-b264-d3941afe9884",
   "metadata": {},
   "source": [
    "### Trying Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47ddd28-e3ae-4387-bcf2-88f877f3a1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "classifier = DecisionTreeClassifier(random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38874b1c-8504-4041-ab05-d1e06af3b09f",
   "metadata": {},
   "source": [
    "### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bb7a4a-ebfb-4142-a70a-3ce68a9f444a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Use the trained model to predict the class for a new vector\n",
    "new_vector = X_train[0]\n",
    "predicted_class = knn_classifier.predict([new_vector])\n",
    "print(f\"Predicted Class for the New Vector: {predicted_class}\\nActual Class: {y_train.values[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11edcc81-69df-4e75-9f8c-4f6af599804d",
   "metadata": {},
   "source": [
    "### No Model, Just document searching?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ae9600-99f1-46e5-a4ed-05c5a056bbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_relevant_documents(input_string, model, tagged_documents):\n",
    "    # Infer the vector representation of the input string\n",
    "    input_vector = model.infer_vector(input_string.split())\n",
    "\n",
    "    # Find similar documents\n",
    "    similar_documents = model.dv.most_similar([input_vector], topn=5)  # Adjust 'topn' as needed\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Input String:\", input_string)\n",
    "    print(\"Relevant Documents:\")\n",
    "    for doc_tag, similarity in similar_documents:\n",
    "        # Find the TaggedDocument based on its tag\n",
    "        relevant_document = next(doc for doc in tagged_documents if doc.tags == doc_tag)\n",
    "        \n",
    "        print(f\"Document Tag: {doc_tag}, Similarity: {similarity}\")\n",
    "        print(\"Document Content:\", relevant_document.words)\n",
    "        print()\n",
    "\n",
    "tokens = \"A big beautiful room\".split()\n",
    "\n",
    "new_vector = model.infer_vector(tokens)\n",
    "sims = model.docvecs.most_similar([new_vector]) #gives you top 10 document tags and their cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d2dd48-3de3-40aa-951a-316e9bff027c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcc25c7-5900-4595-bce3-640864bd5fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for docId, probablity in sims:\n",
    "    for words, tags in tagged_documents:\n",
    "        if docId in tags:\n",
    "            print(f\"------------{docId}------------\")\n",
    "            print(\" \".join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9287a3-5e6f-404b-821f-a7b8be2a92e1",
   "metadata": {},
   "source": [
    "- I have a feeling that KNN approach might work. Let us try that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90fe968-2343-4247-9c4e-12b862d2935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "def find_relevant_documents_knn(input_string, model, vectors, tagged_documents):\n",
    "    # Infer the vector representation of the input string\n",
    "    input_vector = model.infer_vector(input_string.split())\n",
    "\n",
    "    # Use k-Nearest Neighbors to find similar vectors\n",
    "    knn = NearestNeighbors(n_neighbors=5, metric='cosine')  # Adjust 'n_neighbors' as needed\n",
    "    knn.fit(vectors)\n",
    "\n",
    "    # Find indices and distances of k-neighbors\n",
    "    _, indices = knn.kneighbors([input_vector])\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Input String:\", input_string)\n",
    "    print(\"Relevant Documents:\")\n",
    "    for idx in indices.flatten():\n",
    "        print(f\"Document ID: {idx}\")\n",
    "        print(\"Document Content:\", \" \".join(tagged_documents[idx].tags))\n",
    "        print(\"Document Content:\", \" \".join(tagged_documents[idx].words))\n",
    "        print()\n",
    "\n",
    "# Example input string\n",
    "input_string = \"A big beautiful room\"\n",
    "\n",
    "# Find relevant documents using KNN\n",
    "find_relevant_documents_knn(input_string, model, doc_vectors, tagged_documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c2a5be-c7ca-4d69-8fbb-5e2eef9863a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to script config_template.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd984c1-327c-447c-a18a-653a34cd398d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
